{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfd7c6c-1767-4679-8e86-715c5e9e1d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "chroma-hnswlib                           0.7.6\n",
      "chromadb                                 1.0.7\n",
      "llama-index-core                         0.12.34.post1\n",
      "llama-index-embeddings-huggingface       0.5.3\n",
      "llama-index-embeddings-openai            0.3.1\n",
      "llama-index-vector-stores-chroma         0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -q chromadb==1.0.7 llama-index llama-index-core llama-index-embeddings-huggingface tf-keras llama-index-vector-stores-chroma\n",
    "!pip list | grep -e \"index-core\" -e \"index-embeddings\" -e \"chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe15f58-f5a2-4dc2-938f-c577f00e4565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data Path is: /tmp/data_path/, extensions are: .txt\n"
     ]
    }
   ],
   "source": [
    "# load some documents and test the Document Loader class\n",
    "datasource_path: str = \"/tmp/data_path/\"\n",
    "text_data: str = \".txt\"\n",
    "\n",
    "print(f\"Text Data Path is: {datasource_path}, extensions are: {text_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb6867c-f821-4046-b9e6-4c7c1c0e14c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcaimi/.pyenv/versions/3.11.11/envs/jupyter/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "try:\n",
    "    from llama_index.core.ingestion import IngestionPipeline\n",
    "    from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "    from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "    from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "    from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "    from chromadb import Client, Collection\n",
    "except Exception as e:\n",
    "    print(f\"Caught Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a02dd21-b2a0-4215-9029-31adfed1cd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document loaded: 2\n",
      " -> Each document is of type: <class 'llama_index.core.schema.Document'>\n"
     ]
    }
   ],
   "source": [
    "# load the directory with the llamaindex loader \n",
    "loader: SimpleDirectoryReader = SimpleDirectoryReader(input_dir=datasource_path, required_exts=[text_data])\n",
    "\n",
    "# ok, what's inside?\n",
    "data = loader.load_data()\n",
    "print(f\"Number of document loaded: {len(data)}\")\n",
    "print(f\" -> Each document is of type: {type(data[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd6889e-09a5-4e66-b564-e2b61b2f2c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558d297c-476c-4771-b18b-246743072018, None, {'file_path': '/tmp/data_path/rfc2104.txt', 'file_name': 'rfc2104.txt', 'file_type': 'text/plain', 'file_size': 22916, 'creation_date': '2025-05-05', 'last_modified_date': '2025-05-05'}\n",
      "67791bf3-6e60-42b0-83dc-7d32cefddd1d, None, {'file_path': '/tmp/data_path/rfc6248.txt', 'file_name': 'rfc6248.txt', 'file_type': 'text/plain', 'file_size': 10531, 'creation_date': '2025-05-05', 'last_modified_date': '2025-05-05'}\n"
     ]
    }
   ],
   "source": [
    "# print Documents\n",
    "for doc in data:\n",
    "    print(f\"{doc.doc_id}, {doc.embedding}, {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bc7b95-1fc4-4e3d-adc0-566b6a40873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a local embedding function using huggingface embedder\n",
    "embedding_model: str = \"all-MiniLM-L6-v2\"\n",
    "hf_embedder = HuggingFaceEmbedding(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd12bb-4bd0-4ac6-b85c-625c9348821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a local in-memory instance of ChromaDB\n",
    "collection: str = \"jupyter\"\n",
    "chroma_client: Client = Client()\n",
    "chroma_collection: Collection = chroma_client.get_or_create_collection(collection,  metadata={\"hnsw:space\": \"cosine\"})\n",
    "vector_store: ChromaVectorStore = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# ok vector db available\n",
    "print(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059fd5f-1a7c-4bab-8329-1552f9c90573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate ingestion pipeline \n",
    "txt_pipe: IngestionPipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SemanticSplitterNodeParser(embed_model=hf_embedder),\n",
    "        hf_embedder,\n",
    "    ],\n",
    "    vector_store=vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196568e-a138-4b8d-bf78-55fb06e85051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline!\n",
    "res = txt_pipe.run(documents=data)\n",
    "print(f\"Ingested {len(res)} semantically chunked documents\")\n",
    "print(f\"Vector DB contains {chroma_collection.count()} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b01d5a-63cd-4f17-9797-c209a283ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the DB\n",
    "QUERY_TEXT = \"QUESTION\"\n",
    "\n",
    "# embed query\n",
    "query = hf_embedder.get_text_embedding(QUERY_TEXT)\n",
    "\n",
    "# query the vector database\n",
    "index: VectorStoreIndex = VectorStoreIndex.from_vector_store(vector_store=vector_store, embed_model=hf_embedder)\n",
    "retriever = index.as_retriever(similarity_top_k=5, embed_model=hf_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ea26f-e7a7-4f0b-82e4-99c8f3e0d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve and print results\n",
    "top_k = retriever.retrieve(QUERY_TEXT)\n",
    "print(f\"Found {len(top_k)} documents\")\n",
    "\n",
    "# display scores\n",
    "for item in top_k:\n",
    "    print(f\"ID: [{item.id_}] - Score: {item.score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807f2cb-9e4e-4446-a67b-08b257c93cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate node splitter pipeline (no embeddings)\n",
    "ns_pipeline: IngestionPipeline = IngestionPipeline(\n",
    "    transformations=[SemanticSplitterNodeParser(embed_model=hf_embedder)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd8476-0b08-4614-8006-ffac7ba7db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run node splitter\n",
    "ns_res = ns_pipeline.run(documents=data)\n",
    "print(f\"Produced {len(ns_res)} Semantically Correlated Nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27869647-a9c5-4032-bf0e-036f26758f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split nodes in batches\n",
    "batch_num: int = 5\n",
    "nodes_len: int = len(ns_res)\n",
    "print(f\"Splitting {nodes_len} nodes in {batch_num} batches\")\n",
    "\n",
    "# split and return\n",
    "step: int = nodes_len//batch_num\n",
    "batches: list = []\n",
    "if (step > 0):\n",
    "    for k in range(0, nodes_len, step):\n",
    "        batches.append(ns_res[k:k+step])\n",
    "else:\n",
    "    print(f\"Refusing to split: Cannot prepare batches of {step} length\")\n",
    "\n",
    "from numpy import cumsum\n",
    "print(f\"Generated {len(batches)} batches of size {step}\")\n",
    "print(cumsum([len(x) for x in batches]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
